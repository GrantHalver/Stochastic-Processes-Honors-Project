---
title: "Honors Project"
author: "Grant Halver"
date: "April 24, 2019"
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(dev = 'pdf')
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

## Introduction

The Metropolis-Hastings Algorithm is an approximation of generating samples from a distribution $\pi(x)$. A move is accepted with probability $r(x, y) = min\{\frac{\pi(y)q(y, x)}{\pi(x)q(x, y)}, 1\}$. The transition probability is $p(x, y) = q(x, y)r(x, y)$. This may be used to approximate samples from any distribution, like a geometric distribution, but the method is more useful for continuous distributions like the Rayleigh Distribution.

## Geometric Distribution

For the geometric distribution, we can check that the Metropolis-Hastings Algorithm produces a distribution that converges to the geometric distribution. A geometric distribution has $\pi(x) = \theta^x(1-\theta)$ for $x = 1,2,3,...$. To generate the jumps, a symmetric random walk $q(x, x+1) = q(x, x-1) = 1/2$ will be used. By symmetry, $r(x, y) = min\{\pi(y)/\pi(x), 1\}$. When $x>0$, then $\pi(x-1)>\pi(x)$ so $\pi(x-1)/\pi(x)>1$ and $\pi(x+1)/\pi(x) = \theta$. Thus, $p(x, x-1) = 1/2$, $p(x+1, x) = \theta/2$, and $p(x, x) = (1-\theta)/2$. When x = 0, x cannot decrease any further due to the properties of the geometric distribution so $p(0, 1) = \theta/2$ and $p(0, 1) = 1-\theta/2$.

In this example, a geometric distribution with parameter $\theta = 0.5$ was used. Each datapoint on the graph is taken 1000 steps after the the last datapoint. From the graphs below, we can see that the Metropolis-Hasting Algorithm appears to converge to the geometric distribution when the sample size is about 10,000.

```{r, code=readLines("geometric.R"), out.width = '0.5 \\textwidth'}
```

## Rayleigh Distribution

However, the main purpose of the Metropolis-Hastings algorithm is to approximate continuous distributions so we shall also make plots for a continuous distribution, the Rayleigh Distribution.

```{r, fig.align='center', out.width = '0.6 \\textwidth'}
f <- function(x, sigma) {
  if (any(x < 0)) return (0)
  stopifnot(sigma > 0)
  return((x / sigma^2) * exp(-x^2 / (2*sigma^2)))
}

m <- 10000
sigma <- 4
x <- numeric(m)
x[1] <- rchisq(1, df=1)
k <- 0
u <- runif(m)

for(i in 2:m) {
  xt <- x[i-1]
  y <- rchisq(1, df = xt)
  num <- f(y, sigma) * dchisq(xt, df = y)
  den <- f(xt, sigma) * dchisq(y, df = xt)
  if (u[i] <= num/den) x[i] <- y else {
    x[i] <- xt
    k <- k+1 #y is rejected
  }
}

index <- 5000:5500
y1 <- x[index]
plot(index, y1, type="l", main="", ylab="x")
```

This plot gives the time index of the Metropolis-Hastings algorithm along the longitudinal axis and the x value along the latitudinal axis. Notice that when the next move is rejected, there are horizontal lines where the x value does not change.

```{r, fig.align='center', out.width = '0.6 \\textwidth'}
b <- 2001 #discard the burnin sample
y <- x[b:m]
a <- ppoints(100)
QR <- sigma * sqrt(-2 * log(1 - a)) #quantiles of Rayleigh
Q <- quantile(x, a)

qqplot(QR, Q, main="", xlab="Rayleigh Quantiles", ylab="Sample Quantiles")
```

Notice that the data appear to follow a linear trend, so the data generate using the Metropolis-Hastings Algorithm appear to follow the Rayleigh distribution.

```{r, fig.align='center', out.width = '0.6 \\textwidth'}
hist(y, breaks="scott", main="", xlab="", freq=FALSE)
lines(QR, f(QR, 4))
```

On this histogram we can see that the data are distributed approximately the same as the Rayleigh distribution. Hence, the Metropolis-Hastings algorithm generated data that follow the Rayleigh distribution.

## Conclusion

The Metropolis-Hastings algorithm generates samples that follow the desired distribution. This can be used for both discrete and continuous distributions.